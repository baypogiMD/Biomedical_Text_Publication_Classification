# 05_predictive_modeling

## Objective

Train, evaluate, and compare multiple supervised machine learning models for biomedical publication classification using engineered text features, following rigorous evaluation standards.

---

## 1. Environment Setup

```python
import numpy as np
import pandas as pd
from sklearn.linear_model import LogisticRegression
from sklearn.svm import LinearSVC
from sklearn.ensemble import RandomForestClassifier
from sklearn.metrics import classification_report, confusion_matrix, accuracy_score
import seaborn as sns
import matplotlib.pyplot as plt
import joblib

plt.rcParams['figure.figsize'] = (8, 6)
```

---

## 2. Load Engineered Features

```python
X_train = np.load("../data/processed/X_train_svd.npy")
X_test = np.load("../data/processed/X_test_svd.npy")
y_train = np.load("../data/processed/y_train.npy")
y_test = np.load("../data/processed/y_test.npy")

label_encoder = joblib.load("../models/label_encoder.joblib")
labels = label_encoder.classes_
```

---

## 3. Model 1: Logistic Regression (Baseline)

```python
log_reg = LogisticRegression(max_iter=1000, n_jobs=-1)
log_reg.fit(X_train, y_train)

y_pred_lr = log_reg.predict(X_test)
```

```python
print("Logistic Regression Accuracy:", accuracy_score(y_test, y_pred_lr))
print(classification_report(y_test, y_pred_lr, target_names=labels))
```

```python
sns.heatmap(confusion_matrix(y_test, y_pred_lr), annot=True, fmt='d', cmap='Blues',
            xticklabels=labels, yticklabels=labels)
plt.title("Logistic Regression Confusion Matrix")
plt.ylabel("True Label")
plt.xlabel("Predicted Label")
plt.show()
```

```python
joblib.dump(log_reg, "../models/logistic_regression.joblib")
```

---

## 4. Model 2: Linear Support Vector Machine

```python
svm = LinearSVC()
svm.fit(X_train, y_train)

y_pred_svm = svm.predict(X_test)
```

```python
print("Linear SVM Accuracy:", accuracy_score(y_test, y_pred_svm))
print(classification_report(y_test, y_pred_svm, target_names=labels))
```

```python
sns.heatmap(confusion_matrix(y_test, y_pred_svm), annot=True, fmt='d', cmap='Greens',
            xticklabels=labels, yticklabels=labels)
plt.title("Linear SVM Confusion Matrix")
plt.ylabel("True Label")
plt.xlabel("Predicted Label")
plt.show()
```

```python
joblib.dump(svm, "../models/linear_svm.joblib")
```

---

## 5. Model 3: Random Forest (Nonlinear Benchmark)

```python
rf = RandomForestClassifier(
    n_estimators=300,
    max_depth=None,
    random_state=42,
    n_jobs=-1
)
rf.fit(X_train, y_train)

y_pred_rf = rf.predict(X_test)
```

```python
print("Random Forest Accuracy:", accuracy_score(y_test, y_pred_rf))
print(classification_report(y_test, y_pred_rf, target_names=labels))
```

```python
sns.heatmap(confusion_matrix(y_test, y_pred_rf), annot=True, fmt='d', cmap='Oranges',
            xticklabels=labels, yticklabels=labels)
plt.title("Random Forest Confusion Matrix")
plt.ylabel("True Label")
plt.xlabel("Predicted Label")
plt.show()
```

```python
joblib.dump(rf, "../models/random_forest.joblib")
```

---

## 6. Model Comparison Summary

```python
results = pd.DataFrame({
    'Model': ['Logistic Regression', 'Linear SVM', 'Random Forest'],
    'Accuracy': [
        accuracy_score(y_test, y_pred_lr),
        accuracy_score(y_test, y_pred_svm),
        accuracy_score(y_test, y_pred_rf)
    ]
})

results
```

---

## 7. Key Findings

* Linear models perform strongly on TF-IDF + SVD features
* Logistic Regression offers interpretability and stability
* Linear SVM often achieves highest margin-based accuracy
* Random Forest serves as a nonlinear baseline but may underperform on sparse semantics

➡️ Proceed next to **06_model_interpretability.ipynb**
